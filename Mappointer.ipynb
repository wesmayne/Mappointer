{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mappointer\n",
    "#### Wes Mayne & Billy Tang\n",
    "*Using Pandas,SLQAlchemy and Google Maps API, pull site geocode data for established TMS sites and write the retrieved mappoint back to the database.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modules\n",
    "import requests\n",
    "import pandas as pd\n",
    "import sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SQL Alchemy\n",
    "user = ''\n",
    "password = ''\n",
    "servername = ''\n",
    "database = ''\n",
    "\n",
    "column = 'CITYTOWN'\n",
    "condition = 'TAS'\n",
    "\n",
    "connection_string = f'mssql+pymssql://{user}:{password}@{servername}/{database}'\n",
    "engine = sqlalchemy.create_engine(connection_string)\n",
    "conn = engine.connect()\n",
    "\n",
    "sql = f\"select SITEID, SITENAME, MPID, ADDRESS1, SUBURB, CITYTOWN, POSTALCODE from SITE where {column} = '{condition}' AND STARTDATE >= CAST(GETDATE() AS DATE)\"\n",
    "#sql = f\"select top 3 SITEID, SITENAME, MPID, ADDRESS1, SUBURB, CITYTOWN, POSTALCODE from SITE where {column} = '{condition}'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#API Info, Add your own\n",
    "API_KEY = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNction\n",
    "def get_mappoint(address):\n",
    "    URL = f'https://maps.googleapis.com/maps/api/geocode/json?address={address}&key={API_KEY}'\n",
    "    r = requests.get(URL)\n",
    "    data = r.json()\n",
    "    loc_type = data['results'][0]['geometry']['location_type']\n",
    "    lat = data['results'][0]['geometry']['location']['lat']\n",
    "    lng = data['results'][0]['geometry']['location']['lng']\n",
    "    \n",
    "    for address in site['search_string']:\n",
    "        return lat, lng, loc_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Pandas \n",
    "\n",
    "site = pd.read_sql(sql, conn)\n",
    "\n",
    "#Concat columns and add '+' in between\n",
    "site['search_string'] = site['ADDRESS1'] + ', ' + site['SUBURB'] + ', ' + site['CITYTOWN']\n",
    "site['search_string'] = site['search_string'].apply(lambda x: str(x).replace(' ', '+'))\n",
    "\n",
    "\n",
    "\n",
    "#Apply get_mappoint function to entire search_string series\n",
    "site['results'] = site['search_string'].apply(get_mappoint)\n",
    "\n",
    "#split 'results' series into 3 new columns and rename headers\n",
    "results = site['results'].apply(pd.Series)\n",
    "results = results.rename(columns = lambda x : 'results' + str(x))\n",
    "\n",
    "#rename to proper names\n",
    "results = results.rename(columns = {\"results0\": \"Y\", \n",
    "                                  \"results1\":\"X\", \n",
    "                                  \"results2\": \"loc_type\"}) \n",
    "\n",
    "#join columns back into original dataframe\n",
    "site = pd.concat([site[:], results[:]], axis=1)\n",
    "\n",
    "#select relevant columns from site\n",
    "clean_site = site[['SITENAME', 'SITEID','MPID', 'X', 'Y', 'loc_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\wmayne\\envs\\env\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#add column for SQL mappoint INSERT query\n",
    "clean_site['mappoint_query'] = 'INSERT INTO MAPPOINT(MAPPOINT, X, Y, MPCLASSID, APPROXIMATE, SNAP_X, SNAP_Y) VALUES('+\"'\"+clean_site['SITENAME']+\"','\"+clean_site['X'].map(str)+\"','\"+clean_site['Y'].map(str)+\"','-1', 'F','\"+clean_site['X'].map(str)+\"','\"+clean_site['Y'].map(str)+\"')\"     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export to Excel file \n",
    "export = clean_site.to_excel(r'C:\\Users\\wmayne\\OneDrive - Lion Pty Ltd\\Documents\\site.xlsx', index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
